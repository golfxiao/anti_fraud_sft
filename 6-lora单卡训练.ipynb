{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba2f3e4-a483-409d-869b-868309380903",
   "metadata": {},
   "source": [
    "## 引言\n",
    "前文[欺诈文本分类微调（四）：构造训练/测试数据集](https://golfxiao.blog.csdn.net/article/details/141325192)已经构造出了数据集，加上之前[欺诈文本分类微调（一）：基座模型选型](https://golfxiao.blog.csdn.net/article/details/141168571)选好的基座模型，这篇文章将基于构造出的数据集和选定的模型进行欺诈文本分类的微调训练。\n",
    "\n",
    "关于微调方法，我们将使用比较普遍的Lora——在模型中注入低秩矩阵的方式。\n",
    "关于训练器，使用transformers库中提供的Trainer类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faeca06-de74-49f6-be0e-0b861f4578bf",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "#### 加载数据\n",
    "导入要使用的基础包，其中：\n",
    "> - AutoModelForCausalLM:用于加载模型\n",
    "> - AutoTokenizer:用于加载token分词器\n",
    "> - TrainingArguments:用于配置训练参数\n",
    "> - Trainer:用于训练模型\n",
    "> - EarlyStoppingCallback:用于提前结束训练，当评估损失不再下降时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4430408-d4d7-4f4f-aed8-78b5e612830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from peft import LoraConfig, TaskType, get_peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9969a9-ae4c-4b1b-80d0-c39d63224d66",
   "metadata": {},
   "source": [
    "声明数据集和基座模型的路径，以及微调后模型参数的输出路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f321c675-60c5-4b03-a049-b8f8817da65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_path = '/data2/anti_fraud/dataset/train0819.jsonl'\n",
    "evaldata_path = '/data2/anti_fraud/dataset/eval0819.jsonl'\n",
    "model_path = '/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct'\n",
    "output_path = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0819_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be0568-4883-40c3-84cd-6a1dad6fc4ad",
   "metadata": {},
   "source": [
    "定义工具函数用于加载数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716d3019-ead6-48c2-b914-8de0ca1dd84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "def view_data_distribution(data_path, show_first=False):\n",
    "    df = load_jsonl(data_path)\n",
    "    print(f\"total_count:{df.shape[0]}, true_count: {df['label'].sum()}, false_count: {(df['label']==False).sum()}\")\n",
    "    print(json.dumps(df.iloc[0].to_dict(), indent=4, ensure_ascii=False)) if show_first else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a5e188b-4fd3-4047-aafb-d8f28b0fd6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count:18787, true_count: 9377, false_count: 9410\n",
      "{\n",
      "    \"input\": \"发言人3: 现在我所在这个哪里能够工艺能够去把屈光做得很好的，去到这个省级医院是自治区医院跟广西医科大学这个附属医院他们还可以，他们一直保持比较好的一个一个手术量。\\n发言人1: 就是\",\n",
      "    \"label\": false,\n",
      "    \"fraud_speaker\": \"\",\n",
      "    \"instruction\": \"\\n下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true/false)。\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "view_data_distribution(traindata_path, show_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4376e3-614c-4ad6-9c0a-2007f67d79e3",
   "metadata": {},
   "source": [
    "#### 数据序列化\n",
    "\n",
    "如上所示，原始的训练数据是文本形式，而模型推理需要的输入是数字，这中间需要用tokenizer进行文本到数字的序列化转换。\n",
    "\n",
    "每个语言模型内部都维护了一个词表，里面维护了模型认识的所有词与数字编号的映射，不同模型的词表是不一样的，我们需要使用基座模型所对应的词表来创建tokenizer。\n",
    "\n",
    "> Tokenizer是一个词元生成器，它首先通过分词算法将文本切分成独立的token列表，再通过词表映射将每个token转换成语言模型可以处理的数字。详情见[语言模型解构——Tokenizer](https://golfxiao.blog.csdn.net/article/details/138781653)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2342995-1399-45bf-abac-e46462879fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Tokenizer(name_or_path='/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False, trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d3f5e2-f578-49d0-acd5-73fcdbdeff69",
   "metadata": {},
   "source": [
    "> 上面这个tokenizer的输出信息显示：词表中共有151643个词元，这个模型支持最大32KB的序列长度，并且还定义了开始标记<|im_start|>、结束标记<|im_end|>、填充标记<|endoftext|>，这些特殊token需要在数据预处理时被正确的添加到文本中。\n",
    "\n",
    "我们尝试用这个tokenizer序列化一个简单文本看看序列化后的数据长什么模样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9f4950-079b-4714-ac9a-76e237ad2482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [105043, 100165], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"你是谁\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73040d0a-a2e2-470d-be99-89834ac0e98c",
   "metadata": {},
   "source": [
    "input_ids就是`你是谁`序列化成token列表后的数字形式，attention_mask是一个与input_ids长度相同的数组，用于指示模型应该关注哪些token，以及忽略哪些token，填充(padding)token在模型推理时通常应该被忽略。\n",
    "\n",
    "> 注：attention_mask的值通常为0或1，1表示该位置的token是有效的输入（模型应该关注这个token）, 0表示该位置的token是填充（padding），模型在处理时应忽略此token。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04edc0-ffd5-4b9c-8f98-70ac1b68cbc3",
   "metadata": {},
   "source": [
    "\n",
    "定义输入文本的预处理函数，作用是按模型的输入要求将输入文本转换为输入、掩码、标签三个序列。\n",
    "待办：优化process_func为apply方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161210e3-72b2-4634-a60f-1e26a29e207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(item, tokenizer, max_length=2048):\n",
    "    system_message = \"You are a helpful assistant.\"\n",
    "    user_message = item['instruction'] + item['input']\n",
    "    assistant_message = json.dumps({\"is_fraud\":item[\"label\"]}, ensure_ascii=False)\n",
    "    \n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(f\"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{user_message}<|im_end|>\\n<|im_start|>assistant\\n\", add_special_tokens=False)  \n",
    "    response = tokenizer(assistant_message, add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]  \n",
    "    # -100是一个特殊的标记，用于指示指令部分的token不应参与损失计算\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]  \n",
    "    \n",
    "    # 对输入长度做一个限制保护，超出截断\n",
    "    return {\n",
    "        \"input_ids\": input_ids[:max_length],\n",
    "        \"attention_mask\": attention_mask[:max_length],\n",
    "        \"labels\": labels[:max_length]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d69f82-6142-42f8-aff3-456bcb2485fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "使用preprocess函数来预处理所有数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "063a1c3a-88f4-4d3b-bd0d-416e61b6bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path, eval_path, tokenizer):\n",
    "    train_df = load_jsonl(train_path)\n",
    "    train_ds = Dataset.from_pandas(train_df)\n",
    "    train_dataset = train_ds.map(lambda x: preprocess(x, tokenizer), remove_columns=train_ds.column_names)\n",
    "    \n",
    "    eval_df = load_jsonl(eval_path)\n",
    "    eval_ds = Dataset.from_pandas(eval_df)\n",
    "    eval_dataset = eval_ds.map(lambda x: preprocess(x, tokenizer),  remove_columns=eval_ds.column_names)\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa897c4e-f84f-4458-93e5-f2f44dc2f45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d89332e1e8435e802b05feaae86089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18787 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8b5ff90ee94cc98f73975b6ea66613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2348 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 18787\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset, eval_dataset = load_dataset(traindata_path, evaldata_path, tokenizer)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad6a85-8e45-4f01-8eb9-64a2bad2808f",
   "metadata": {},
   "source": [
    "查看下序列化后的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dcad7ca-ec78-4d4e-980c-8a1a2400004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Input IDs: [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 271, 100431, 99639, 37474, 105051, 108704, 11, 220, 14880, 101042, 105051, 43815, 107189, 106037, 101052, 3837, 23031, 2236, 68805, 66017, 103929, 104317, 59151, 9623, 761, 97957, 25, 830, 91233, 8, 8997, 110395, 18, 25, 10236, 236, 108, 102865, 101393, 99487, 101314, 100006, 101189, 100006, 85336, 99360, 102683, 99225, 106630, 104528, 3837, 85336, 26939, 99487, 104671, 100634, 20412, 104917, 100634, 99557, 104366, 115203, 99487, 108398, 100634, 99650, 104468, 3837, 99650, 99725, 100662, 99792, 99692, 46944, 46944, 104160, 32757, 8997, 110395, 16, 25, 58230, 109, 20412, 151645, 198, 151644, 77091, 198, 4913, 285, 761, 97957, 788, 895, 92, 151643], Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], Labels: [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4913, 285, 761, 97957, 788, 895, 92, 151643]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Input IDs: {train_dataset[0]['input_ids']}, Attention Mask: {train_dataset[0]['attention_mask']}, Labels: {train_dataset[0]['labels']}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8228c3-6887-4653-a686-4a6046bb6002",
   "metadata": {},
   "source": [
    "输出结果是一堆数字，这是给模型处理的。给人肉眼看的话可以将其反序列化为文本形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6ca2b4-8960-46c4-a6cb-2d565aa58893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n\\n下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true/false)。\\n发言人3: 现在我所在这个哪里能够工艺能够去把屈光做得很好的，去到这个省级医院是自治区医院跟广西医科大学这个附属医院他们还可以，他们一直保持比较好的一个一个手术量。\\n发言人1: 就是<|im_end|>\\n<|im_start|>assistant\\n{\"is_fraud\": false}<|endoftext|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cff80a-998e-46a3-b158-37cdef2568a5",
   "metadata": {},
   "source": [
    "输出labels中我们添加了大量的-100特殊标记，将其过滤掉后再输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a9ac061-8827-4d00-b309-5c55777a610c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"is_fraud\": false}<|endoftext|>'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(filter(lambda x: x != -100, train_dataset[0][\"labels\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e2818-df22-40db-aec9-b61f39218274",
   "metadata": {},
   "source": [
    "## 模型准备\n",
    "\n",
    "指定设备，这里先使用单机单卡。\n",
    "- 通过环境变量 CUDA_VISIBLE_DEVICES来指定当前进程可以使用的GPU卡范围。\n",
    "- device指定模型需要使用的设备，我们只用一个设备，直接指定cuda即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33abe2b-f0da-4cc2-8bdb-c50417b0a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定可以使用的GPU设备\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "# 当有多张卡时，device_map=\"auto\"参数会自动把模型切分到多张GPU卡上，如果不希望这么做，改为事后to(device)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792c14e-3b0e-4e80-8806-055712d5be41",
   "metadata": {},
   "source": [
    "#### 加载模型\n",
    "先将模型加载进内存，再使用model.to(device)将模型从内存移到指定的GPU设备上，这里用的模型比较小加上资源有限，数据类型使用半精度16位即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f581b98-bc98-429a-919b-dc8147b41b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(model_path, device='cuda'):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path,torch_dtype=torch.bfloat16)\n",
    "    model.enable_input_require_grads() # 开启梯度检查点时，要执行该方法\n",
    "    return model.to(device)\n",
    "\n",
    "model = load_model(model_path, device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76878f01-dd54-4f16-92eb-8090e5f00953",
   "metadata": {},
   "source": [
    "> 这里可以清晰看到qwen2模型的结构,最开始是一个向量嵌入层，紧接着是Attention和MLP组成的28层DecodeLayer,最后有一个用于分类的输出层。\n",
    "\n",
    "#### 插入微调参数矩阵\n",
    "使用Lora进行微调时，需要修改模型结构，这里将一个rank=8的低秩矩阵插入到模型的每个DecodeLayer层中，在训练时只学习这个低秩矩阵，原模型的参数不改变。\n",
    "- target_modules：定义了要对模型的哪些块做修改，准确来说是在具体哪些块中插入低秩矩阵。\n",
    "- r: 低秩矩阵的秩大小，值越小，模型能学习的参数越少，这里使用默认的8.\n",
    "- lora_alpha： 一个缩放比例因子，控制着模型推理过程中将LoRA参数在模型整个参数中所占的比重大小，这里也按推荐配置为r的2倍。\n",
    "- lora_dropout: 训练过程中，随机丢弃的神经元比例，目的是引入随机性来增强模型的泛化能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab60b9d-3e84-423b-8cdc-1664a035a51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(151936, 1536)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2SdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Qwen2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=8960, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=8960, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8960, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm()\n",
       "            (post_attention_layernorm): Qwen2RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_peft_model(model):\n",
    "    config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM, \n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        inference_mode=False, # 训练模式\n",
    "        r=8, \n",
    "        lora_alpha=16,   \n",
    "        lora_dropout=0.05\n",
    "    )\n",
    "    return get_peft_model(model, config)\n",
    "\n",
    "peft_model = build_peft_model(model)\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade3f40-e5d0-4e9a-bb77-a3adcbcc2407",
   "metadata": {},
   "source": [
    "查看此模型要训练的参数量，从参数量能看出来，只有插入的lora低秩矩阵部分需要学习。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b61b3dc3-669c-4bc1-89c2-c881dc4897ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9,232,384 || all params: 1,552,946,688 || trainable%: 0.5945\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccabf4f-e3e4-4623-bd0e-e01f1b268777",
   "metadata": {},
   "source": [
    "#### 构建训练器\n",
    "配置训练参数，这块是后期需要重点关注和调整的地方，本次是初次微调，先使用默认参数看看效果再调整，一些参数的理解如下：\n",
    "- per_device_train_batch_size：每个设备单次运算的小批量大小，默认值未更改。\n",
    "- gradient_accumulation_steps：梯度累积的步骤数，原本是每4条数据更新一次参数，加上梯度累积=4后相当于每16条数据更新一次参数，相当于变相增加batch_size大小。\n",
    "- num_train_epochs：训练的总轮数，默认值为3，相当于所有数据训练3遍。\n",
    "- eval_strategy: 评估策略，可选有steps和epochs\n",
    "- eval_steps：训练多少步评估一次模型性能，每个batch_size为一步，此参数在eval_strategy=steps时适用。\n",
    "- save_steps：训练多少步自动保存一次模型参数。\n",
    "- learning_rate：学习率，默认值未更改。\n",
    "- load_best_model_at_end：训练结束时自动加载最佳模型\n",
    "- gradient_checkpointing：是否启用梯度检查点，启用梯度检查点可以减少kvcache对内存的占用，能节省内存。\n",
    "\n",
    "> 据实际测试：对于1.5B batch_size=4的训练场景，未启用梯度检查点时会占用22G的显存，启用后能降到17G左右，效果还是很明显的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b21d1790-137a-4d7c-9a74-693026e18b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_arguments(output_path):\n",
    "    return TrainingArguments(\n",
    "        output_dir=output_path,\n",
    "        per_device_train_batch_size=4,  # 每个设备（如每个GPU）的训练批次大小\n",
    "        gradient_accumulation_steps=4,  # 梯度累积的步骤数，相当于增大批次大小\n",
    "        logging_steps=10,                \n",
    "        num_train_epochs=3,    \n",
    "        eval_strategy=\"steps\",  \n",
    "        eval_steps=10, # 设置评估的步数，与保存步数一致\n",
    "        save_steps=10, # 为了快速演示，这里设置20，建议设置成100\n",
    "        learning_rate=1e-4,\n",
    "        save_on_each_node=True,\n",
    "        load_best_model_at_end=True, # 在训练结束时加载最佳模型\n",
    "        gradient_checkpointing=True  #  启用梯度检查点以节省内存\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f2741-8fbf-4c90-a2ec-31c6bd3e9b83",
   "metadata": {},
   "source": [
    "构建训练器的参数不多，重点理解以下几个：\n",
    "- eval_dataset：评估数据集，设置了此参数才会在训练过程中自动评估模型的性能，Validation Loss指标才会有值，相当于边训练边验证效果。\n",
    "- data_collator：控制如何将原始数据合并成批(batch), DataCollatorForSeq2Seq 会自动处理输入序列的填充，使用 tokenizer 提供的填充标记（padding token）将不同长度的序列填充到相同的长度，以避免在训练过程中因序列长度不同而产生错误。\n",
    "    > 注：序列到序列（Seq2Seq）模型中，批量输入的多条文本数据通常具有不同的长度，而模型在进行矩阵运算时需要同一批次的数据有相同长度才能一起运算，否则会报错，所以需要指定padding=True参数来将输入序列填充到相同长度。\n",
    "- EarlyStoppingCallback：用于设置提前结束训练的回调，early_stopping_patience=3表示验证指标没有改进时经过3个评估周期后提前停止训练。\n",
    "    > 注：默认情况下，训练会跑满train_dataset和num_train_epochs指定的所有数据集和训练轮次，但存在一些场景（例如过拟合发生时）需要提前结束训练，此时就可以设置早停回调以免模型越训练越差，还有一个重要的点是避免浪费GPU算力成本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a0db73e-5e9e-43ce-83ee-8b1bc8e63e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trainer(model, tokenizer, args, train_dataset, eval_dataset):\n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # 早停回调\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca767e2-0fee-472d-a08f-1a2696ad7abf",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "\n",
    "基于前面准备的数据集和模型来构建一个训练器，调用trainer.train()方法即开始训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b46e3d9-8626-45dd-8516-43176e11826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='3522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  90/3522 12:40 < 8:14:34, 0.12 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.040756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.034393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.030982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.029448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.028482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.027626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.031344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.033409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.031232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=90, training_loss=0.0323091435763571, metrics={'train_runtime': 762.4751, 'train_samples_per_second': 73.918, 'train_steps_per_second': 4.619, 'total_flos': 2991778113798144.0, 'train_loss': 0.0323091435763571, 'epoch': 0.07664466680860124})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = build_trainer(peft_model, tokenizer, build_train_arguments(output_path), train_dataset, eval_dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d0c2ed-d95a-44bd-898a-ca88f6041fd3",
   "metadata": {},
   "source": [
    "这个训练结束的有点快，可能是提前结束的设置项起到了作用。先评估下模型训练的效果，这里使用jupyter魔法命令%run直接引入[前文](https://golfxiao.blog.csdn.net/article/details/141355995)已经构建的评估代码，基于指定的测试集来测试模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "084dbf43-cf60-44fa-b320-25d95187d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40715afa-e99c-48cc-a7b8-8c38f0e3a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [19:22<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1107, fp:60, fn:322, tp:860\n",
      "precision: 0.9347826086956522, recall: 0.727580372250423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testdata_path = '/data2/anti_fraud/dataset/test0819.jsonl'\n",
    "evaluate_with_model(peft_model, tokenizer, testdata_path, device, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf33d98a-02b5-4b04-bac9-dfc32adfb29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2348/2348 [19:12<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1041, fp:124, fn:96, tp:1087\n",
      "precision: 0.8976052848885219, recall: 0.9188503803888419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0819_1/checkpoint-90'\n",
    "evaluate(model_path, checkpoint_path, evaldata_path, device, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe5389c-5244-4451-9273-fcb4ed282379",
   "metadata": {},
   "source": [
    "> 为何使用最后一次checkpoint-90验证的性能和直接使用peft_model验证的结果不一致？\n",
    "> 原因：训练参数中`load_best_model_at_end=True`这个选项，会在训练结束后自动加载性能最佳的模型，也就是评估损失最低的模型，在我们的训练中，评估损失最低的是checkpoint-60的0.027，而不是checkpoint-90的0.031，由于所评测的checkpoint（也就是模型）不同，自然结果也不一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1e12a-9d0a-4d07-a00e-928a3cf23434",
   "metadata": {},
   "source": [
    "相比于[欺诈文本分类微调（五）：模型评测](https://golfxiao.blog.csdn.net/article/details/141355995)中对基座模型的评测结果（precision: 0.8805, recall: 0.4576）来看，这个训练的精确率和召回率都有提升，而且召回率提升幅度还比较大。\n",
    "\n",
    "\n",
    "这个结果是不是看起来还行？其实事情并没有这么顺利，在这个训练之前还进行过两轮训练，相比这个来说，效果就有些差了，不过我还是想把它们贴在这里，以便我们从中吸取经验和教训。\n",
    "\n",
    "#### 失败的尝试记录——1\n",
    "在上面这轮训练之前有一轮训练，与上面最大的区别是两个lora参数：`lora_alpha=32, lora_dropout=0.1`,如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dcfd20f-1f34-4bd1-8a7f-f474f6711838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(151936, 1536)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2SdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Qwen2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=8960, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=8960, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8960, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm()\n",
       "            (post_attention_layernorm): Qwen2RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_peft_model(model):\n",
    "    config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM, \n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        inference_mode=False, # 训练模式\n",
    "        r=8, \n",
    "        lora_alpha=32,   \n",
    "        lora_dropout=0.1\n",
    "    )\n",
    "    return get_peft_model(model, config)\n",
    "\n",
    "peft_model2 = build_peft_model(model)\n",
    "peft_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84566923-e8b1-428f-80bc-abcea0575bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-22 21:59:55,151] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='3522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  80/3522 11:10 < 8:13:23, 0.12 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.057084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.033191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.028215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.027536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.026891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.027571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.031012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.027318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.06814795173704624, metrics={'train_runtime': 673.4243, 'train_samples_per_second': 83.693, 'train_steps_per_second': 5.23, 'total_flos': 2662222676484096.0, 'train_loss': 0.06814795173704624, 'epoch': 0.06812859271875665})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path2 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0819_2'\n",
    "trainer2 = build_trainer(peft_model2, tokenizer, build_train_arguments(output_path2), train_dataset, eval_dataset)\n",
    "trainer2.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee026d-82bd-4d99-91bb-88580bb01895",
   "metadata": {},
   "source": [
    "运行评估测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9a89548-67e0-4538-a76d-5103939c6e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [18:50<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1148, fp:19, fn:595, tp:587\n",
      "precision: 0.9686468646864687, recall: 0.4966159052453469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testdata_path = '/data2/anti_fraud/dataset/test0819.jsonl'\n",
    "evaluate_with_model(peft_model2, tokenizer, testdata_path, device, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b112eb-62e2-4814-8689-6388acf0df2b",
   "metadata": {},
   "source": [
    "这个结果中，精确率还好些，但召回率`0.4966`相比于前面的`0.7275`就差距比较多了，也只比基座模型的0.4576好一点点。\n",
    "\n",
    "之所以差别这么大，应该是lora_alpha/r=2还是lora_alpha/r=4的这个比值不同所导致的原因，曾有论文实际验证过，这个比值等于2时有最好的效果，参考[使用 LoRA 微调 LLM 的实用技巧](https://www.jiqizhixin.com/articles/2023-12-04-14)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e202983-0b45-406d-9f6f-1fda5bee300f",
   "metadata": {},
   "source": [
    "#### 失败的尝试记录-2\n",
    "\n",
    "如果只用正向数据集来训练会怎么样？刚开始学习一门技术总是想亲自演练各种可能性带来的效果，以此来建立自己对这门技术最基本的认知。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "509fa79d-72a9-4f8e-aa3b-de63c92a13d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count:21792, true_count: 21792, false_count: 0\n",
      "total_count:5464, true_count: 5464, false_count: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata_path3 = '/data2/anti_fraud/dataset/train.jsonl'\n",
    "testdata_path3 = '/data2/anti_fraud/dataset/test.jsonl'\n",
    "\n",
    "view_data_distribution(traindata_path3), view_data_distribution(testdata_path3), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5e849-ec5a-44b7-a116-0e30419d7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "上面的数据分布可以看出，这个数据集只有正向数据集，没有反向数据集，下面用这个数据集进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f90a931-ed6f-4cff-96fe-db1a9476dd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147dbd23e6334c73a9838ad485d9c020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d2b1d167e74701856ec91d0f14dc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5464 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='4086' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  80/4086 07:23 < 6:20:01, 0.18 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=2.9383825705053824e-06, metrics={'train_runtime': 445.6354, 'train_samples_per_second': 146.703, 'train_steps_per_second': 9.169, 'total_flos': 3645473460867072.0, 'train_loss': 2.9383825705053824e-06, 'epoch': 0.05873715124816446})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path3 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0819_3'\n",
    "\n",
    "train_dataset3, eval_dataset3 = load_dataset(traindata_path3, testdata_path3, tokenizer)\n",
    "trainer3 = build_trainer(peft_model2, tokenizer, build_train_arguments(output_path3), train_dataset3, eval_dataset3.select([i for i in range(1000)]))\n",
    "trainer3.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a88e56-903e-4add-a0c9-e2063ba5472a",
   "metadata": {},
   "source": [
    "这个训练的过程很奇特，只有不到10个step损失就降为了0，相当于模型很聪明，才刚走了几步路，就发现有一条直达终点的捷径，这条捷径在所给的训练数据集上非常有效。\n",
    "\n",
    "但在未知数据上效果怎么样，还要评测一下才能见分晓。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc84ddc9-46b1-4aa0-910d-6fff7d011dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [19:12<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：0, fp:1167, fn:0, tp:1182\n",
      "precision: 0.5031928480204342, recall: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testdata_path = '/data2/anti_fraud/dataset/test0819.jsonl'\n",
    "evaluate_with_model(peft_model2, tokenizer, testdata_path, device, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b186833-586f-4b2b-85c2-ed4aa57a8195",
   "metadata": {},
   "source": [
    "从这个评测的结果上，就能看出，模型所找到的捷径是将所有数据都分类为正（tn和fn为0表示没有反向的）。\n",
    "\n",
    "这里可以得到一条经验：模型很善于找捷径，所以我们在准备训练数据时不能留下误导性的特征给模型去学习。这也是为什么在前面的准备数据环节时，做了很多像长度对齐、均衡分布相关的工作，目的就是去掉误导性的特征，让模型去学习真正的我们期望它去学习的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2410ea-cfab-4ffa-9bcc-16a4039bb32f",
   "metadata": {},
   "source": [
    "**小结**：本文基于lora的思想，在模型结构中插入了独立低秩矩阵进行微调训练，训练结果初见成效。不过，由于配置问题这个训练结束的很早，后面需要调整配置让数据得到充分的训练，以便模型能学习到更多的特征。此外，训练参数目前基本都还是默认值，这块也会有很大的调优空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6320087-127f-4f6f-b1ff-0d05824c8fb3",
   "metadata": {},
   "source": [
    "## 相关阅读\n",
    "- [语言模型解构——Tokenizer](https://golfxiao.blog.csdn.net/article/details/138781653)\n",
    "- [欺诈文本分类微调（四）：构造训练/测试数据集](https://golfxiao.blog.csdn.net/article/details/141325192)\n",
    "- [欺诈文本分类微调（五）：模型评测](https://golfxiao.blog.csdn.net/article/details/141355995)\n",
    "- [使用 LoRA 微调 LLM 的实用技巧](https://www.jiqizhixin.com/articles/2023-12-04-14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
