{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763a3d71-910f-4128-817d-6724e4638e60",
   "metadata": {},
   "source": [
    "## 引言\n",
    "前文[数据校正与增强](https://golfxiao.blog.csdn.net/article/details/142333893)进行了数据增强，本文将使用增强后的数据对模型进行进一步训练，以便得到能同时预测出分类标签、欺诈者、分类原因多个信息的模型。\n",
    "\n",
    "为此，我们需要对整个训练过程进行调整，包括：\n",
    "1. 交叉训练逻辑封装\n",
    "2. 数据序列化的改造\n",
    "3. 评测方法改造想"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320ce50-6b33-44cf-9824-a6cb4cef6a66",
   "metadata": {},
   "source": [
    "## 训练过程\n",
    "\n",
    "#### 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "038f21c2-1d67-4085-970a-c154882a5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0236fa35-d30e-4d42-b80a-cae1a40db473",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_path = '/data2/anti_fraud/dataset/train0902.jsonl'\n",
    "evaldata_path = '/data2/anti_fraud/dataset/eval0902.jsonl'\n",
    "model_path = '/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct'\n",
    "output_path = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0913_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f534275-1f8b-49ce-bbb7-e4d37e520e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57276e83-035d-41ea-be8b-c59c88ed5322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c150fbb4ab43d69198b61bb969f34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24246 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d1e034d8a7445097b8b177097b268c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "train_dataset, eval_dataset = load_dataset(traindata_path, evaldata_path, tokenizer, with_reason=True, lazy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa35d9-ca22-4dc4-b76d-a7cde96bc58e",
   "metadata": {},
   "source": [
    "#### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6612c1d-eff5-4cce-b105-787b50e09682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gc\n",
    "import numpy as np\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35740c33-6a0a-46f2-b961-c3e8c6540ab5",
   "metadata": {},
   "source": [
    "拼接训练集和验证集作为一个数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a7f8569-b568-432a-ae12-ad0510bc3a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27277"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = concatenate_datasets([train_dataset, eval_dataset])\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b6265-2a54-4ed7-8f1e-7bf5843ae152",
   "metadata": {},
   "source": [
    "创建KFold对象用于按折子划分数据集。\n",
    "- n_splits=5：表示将数据集划分为5份。\n",
    "- shuffle=True：表示调用`kf.split`划分数据集前先将顺序打乱。\n",
    "\n",
    "> KFold是由sklearn库提供的k折交叉验证方法，它通过将数据集分成k个相同大小的子集（称为折），每次迭代数据集时，使用其中一个作为验证集，其余4个作为训练集，并重复这个过程k次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48328376-b60d-4806-82d5-67c16d3395be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e3c6ec-7a16-4b1a-aec0-9f270aaadfed",
   "metadata": {},
   "source": [
    "用kfold划分数据集时，实际拿到的是数据在数据集中的索引顺序，如下面示例的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "017abd90-a5b0-4c90-8c8f-1a4f6996bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 27273, 27275, 27276]),\n",
       " array([    5,     7,     8, ..., 27262, 27270, 27274]),\n",
       " 21821,\n",
       " 5456)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = kf.split(np.arange(len(datasets)))\n",
    "train_indexes, val_indexes = next(indexes)\n",
    "train_indexes, val_indexes, len(train_indexes), len(val_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db19b3-4f8f-4429-95d8-312c95e24437",
   "metadata": {},
   "source": [
    "#### 超参数定义\n",
    "\n",
    "定义超参构造函数，包括训练参数和Lora微调参数。这里相对于之前作的调整在于：\n",
    "- 修改评估和保存模型的策略，由每100step改为每个epoch，原因是前者保存的checkpoint有太多冗余。\n",
    "- 将num_train_epochs调整为2，表示每个折子的数据集训练2遍，k=5时数据总共会训练10遍。\n",
    "\n",
    "> 注：当`per_device_train_batch_size=16`时训练过程中会意外发生OOM，所以临时将批次大小per_device_train_batch_size改为8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c33964a-c461-4801-a94a-731465fa40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arguments(output_path):\n",
    "    train_args = build_train_arguments(output_path)\n",
    "    train_args.eval_strategy='epoch'\n",
    "    train_args.save_strategy='epoch'\n",
    "    train_args.num_train_epochs = 2\n",
    "    train_args.per_device_train_batch_size = 8\n",
    "    \n",
    "    lora_config = build_loraconfig()\n",
    "    lora_config.lora_dropout = 0.2   # 增加泛化能力\n",
    "    lora_config.r = 16\n",
    "    lora_config.lora_alpha = 32\n",
    "    return train_args, lora_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe31ef6d-b0cc-4cd8-a549-415ebfb0560d",
   "metadata": {},
   "source": [
    "由于训练过程中需要迭代更换不同的训练集和验证集组合，而更换数据集就需要重新创建训练器，传入新的模型实例。除了第一次训练是从0开始训练，后面几次都需要加载前一轮训练保存的最新checkpoint，以接着之前的结果继续训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92178c-2871-4d61-88ae-4eaa0eecbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "定义一个`find_last_checkpoint`方法，用于从一个目录中查找最新的checkpoint。\n",
    " - glob.glob 函数可以在指定目录下查找所有匹配 `checkpoint-*` 模式的子目录\n",
    " - os.path.getctime 返回文件的创建时间（或最近修改时间）\n",
    " - max 函数根据这些时间找出最后创建的目录，也就是最新的checkpoint。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9952aa5f-38a9-41a0-bbb8-f28e800ed34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_1/checkpoint-3522'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 确定最后的checkpoint目录\n",
    "def find_last_checkpoint(output_dir):\n",
    "    checkpoint_dirs = glob.glob(os.path.join(output_dir, 'checkpoint-*'))\n",
    "    last_checkpoint_dir = max(checkpoint_dirs, key=os.path.getctime)\n",
    "    return last_checkpoint_dir\n",
    "\n",
    "find_last_checkpoint(\"/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebeab97-8c1b-4270-ae0e-5778f5432b86",
   "metadata": {},
   "source": [
    "定义一个新的加载模型的方法，用于从基座模型和指定的checkpoint中加载最新训练的模型，并根据训练目标来设置参数的require_grad属性，这里将来自lora的参数都设置为需要梯度，其余参数设置不可训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a4e5d61-49a7-4eb3-9611-d1f731eac77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_v2(model_path, checkpoint_path='', device='cuda'):\n",
    "    # 加载模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, trust_remote_code=True).to(device)\n",
    "    # 加载lora权重\n",
    "    if checkpoint_path: \n",
    "        model = PeftModel.from_pretrained(model, model_id=checkpoint_path).to(device)\n",
    "    # 将基础模型的参数设置为不可训练\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # 将 LoRA 插入模块的参数设置为可训练\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lora' in name:\n",
    "            param.requires_grad = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09908d7-6512-48b6-b876-04dfe2f9661c",
   "metadata": {},
   "source": [
    "在这个训练过程中，第一次训练用的是从零初始化的微调秩，而后面几次训练则需要从指定checkpoint来初始化微调秩，这导致了[原先的build_trainer方法](https://golfxiao.blog.csdn.net/article/details/141500352)不通用。所以定义一个新的训练器构建方法，将加载微调参数的逻辑移到外面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12a3082-758e-49d9-9106-2a6e2d285b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trainer_v2(model, tokenizer, train_args, train_dataset, eval_dataset):\n",
    "    # 开启梯度检查点时，要执行该方法\n",
    "    if train_args.gradient_checkpointing:\n",
    "        model.enable_input_require_grads()\n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],  # 早停回调\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829169e1-d681-47f2-8c7c-5ed85144bdb5",
   "metadata": {},
   "source": [
    "定义交叉训练的主循环。\n",
    "- kf.split函数划分了5份数据索引，以这5份数据索引进行5次迭代。\n",
    "- 使用`datasets.select`基于索引在每次迭代时选择不同的数据作为训练集和验证集。\n",
    "- 为了避免前次迭代训练的结果被下次迭代的结果给覆盖，每次迭代训练通过fold来拼接不同的输出目录output_path。\n",
    "- 如果存在last_checkpoint_path,则从checkpoint来加载模型，如果不存在，则使用get_peft_model向模型中插入一个新的Lora微调秩。\n",
    "- 使用新的build_trainer_v2方法来构建训练器并开始训练。\n",
    "- 每次迭代完都找出此次训练中最新的checkpoint，作为下次训练的起点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fa085ec-d4dd-4b77-97d4-5238cc79b527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 start, train_index=[    1     2     3 ... 27274 27275 27276], val_index=[    0    13    18 ... 27269 27270 27271]\n",
      "train data: 21821, eval: 5456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n",
      "[2024-09-13 09:45:45,557] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5454' max='5454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5454/5454 1:32:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.780100</td>\n",
       "      <td>0.825167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.696700</td>\n",
       "      <td>0.813522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0, result = TrainOutput(global_step=5454, training_loss=0.8096381610769643, metrics={'train_runtime': 5525.3768, 'train_samples_per_second': 7.898, 'train_steps_per_second': 0.987, 'total_flos': 1.3732846378074931e+17, 'train_loss': 0.8096381610769643, 'epoch': 2.0})\n",
      "fold=1 start, train_index=[    0     1     2 ... 27272 27274 27275], val_index=[    8     9    10 ... 27265 27273 27276]\n",
      "train data: 21821, eval: 5456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5454' max='5454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5454/5454 1:32:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.785400</td>\n",
       "      <td>0.738886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.731676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=1, result = TrainOutput(global_step=5454, training_loss=0.694154640159023, metrics={'train_runtime': 5531.5749, 'train_samples_per_second': 7.89, 'train_steps_per_second': 0.986, 'total_flos': 1.3742528585566618e+17, 'train_loss': 0.694154640159023, 'epoch': 2.0})\n",
      "fold=2 start, train_index=[    0     2     4 ... 27273 27275 27276], val_index=[    1     3     5 ... 27252 27268 27274]\n",
      "train data: 21822, eval: 5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5454' max='5454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5454/5454 1:32:18, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.679400</td>\n",
       "      <td>0.619393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.558900</td>\n",
       "      <td>0.610776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=2, result = TrainOutput(global_step=5454, training_loss=0.5996930905323042, metrics={'train_runtime': 5539.5927, 'train_samples_per_second': 7.879, 'train_steps_per_second': 0.985, 'total_flos': 1.3758353063028326e+17, 'train_loss': 0.5996930905323042, 'epoch': 2.0})\n",
      "fold=3 start, train_index=[    0     1     3 ... 27274 27275 27276], val_index=[    2     6    25 ... 27256 27260 27272]\n",
      "train data: 21822, eval: 5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5454' max='5454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5454/5454 1:32:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>0.503672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.490893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=3, result = TrainOutput(global_step=5454, training_loss=0.4972909716598971, metrics={'train_runtime': 5548.4171, 'train_samples_per_second': 7.866, 'train_steps_per_second': 0.983, 'total_flos': 1.3795531974404506e+17, 'train_loss': 0.4972909716598971, 'epoch': 2.0})\n",
      "fold=4 start, train_index=[    0     1     2 ... 27273 27274 27276], val_index=[    4     7    12 ... 27254 27263 27275]\n",
      "train data: 21822, eval: 5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5454' max='5454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5454/5454 1:32:03, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.394778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.372799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=4, result = TrainOutput(global_step=5454, training_loss=0.3999929018605529, metrics={'train_runtime': 5524.1292, 'train_samples_per_second': 7.901, 'train_steps_per_second': 0.987, 'total_flos': 1.3724994732869222e+17, 'train_loss': 0.3999929018605529, 'epoch': 2.0})\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "last_checkpoint_path = ''\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(np.arange(len(datasets)))):\n",
    "    print(f\"fold={fold} start, train_index={train_index}, val_index={val_index}\")\n",
    "    train_dataset = datasets.select(train_index)\n",
    "    eval_dataset = datasets.select(val_index)\n",
    "    print(f\"train data: {len(train_dataset)}, eval: {len(eval_dataset)}\")\n",
    "\n",
    "    output_path = f'/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0913_{fold}'\n",
    "    train_args, lora_config = build_arguments(output_path)\n",
    "    if last_checkpoint_path:\n",
    "        model = load_model_v2(model_path, last_checkpoint_path, device)\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16).to(device)\n",
    "        model = get_peft_model(model, lora_config)\n",
    "\n",
    "    model.print_trainable_parameters()\n",
    "    trainer = build_trainer_v2(model, tokenizer, train_args, train_dataset, eval_dataset)\n",
    "    train_result = trainer.train()\n",
    "    print(f\"fold={fold}, result = {train_result}\")\n",
    "    results.append(train_result)\n",
    "    \n",
    "    last_checkpoint_path = find_last_checkpoint(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23425a-f83e-4357-99e1-25d6ae5eb301",
   "metadata": {},
   "source": [
    "收集5轮训练的数据。\n",
    "\n",
    "第0轮训练数据：\n",
    "| Epoch |\tTraining Loss\t| Validation Loss |\n",
    "| --- | --- | --- |\n",
    "|1\t| 0.0233 |\t0.02189 | \n",
    "|2\t| 0.0138 | 0.01614 |\n",
    "|3\t| 0.008800 |\t0.011420 |\n",
    "|4\t| 0.004600 |\t0.013666 |\n",
    "|5\t| 0.003200 |\t0.004718 |\n",
    "|6\t| 0.003000 |\t0.004082 |\n",
    "|7\t| 0.007200 |\t0.001999 |\n",
    "|8\t| 0.000000 |\t0.000814 |\n",
    "|9\t| 0.004900 | 0.002273 |\n",
    "|10\t| 0.010200 | 0.002139 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22861379-fa9d-452b-b158-58ea6a2967f1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "对比前面[欺诈文本分类微调（七）—— lora单卡二次调优](https://golfxiao.blog.csdn.net/article/details/141500352)训练进行到2300步左右（大概两遍数据）就开始过拟合，主要现象是验证损失到0.0161就不再下降反而开始升高，K折交叉训练直到第4次迭代（大概八遍数据）过后才达到损失最低点，第5次迭代才出现了略微的过拟合（相比于第4次），过拟合的现象得到了极大的缓解，验证损失也降到了一个更低的值0.000814，这说明数据在训练和验证中被充分的使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3265256d-5938-4a6f-857d-d0cc4c2ac8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 216896\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua       768 Sep 13 17:27 adapter_config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua  73911112 Sep 13 17:27 adapter_model.safetensors\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua 148047722 Sep 13 17:27 optimizer.pt\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua      5140 Sep 13 17:27 README.md\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua     14244 Sep 13 17:27 rng_state.pth\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua      1064 Sep 13 17:27 scheduler.pt\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua     96126 Sep 13 17:27 trainer_state.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua      5240 Sep 13 17:27 training_args.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls -l /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0913_4/checkpoint-5454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332759a-cf6a-45a0-89b1-402259f49f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%run evaluate_v2.py\n",
    "testdata_path = '/data2/anti_fraud/dataset/test0902.jsonl'\n",
    "checkpoint_path = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0913_4/checkpoint-5454'\n",
    "evaluate_v2(model_path, checkpoint_path, testdata_path, device, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c794b894-5eeb-4883-8c32-b278a26096d1",
   "metadata": {},
   "source": [
    "输出的指标信息如下（reason采用的是rouge-1分数）：\n",
    "```\n",
    "is_fraud字段指标:\n",
    "tn：1403, fp:90, fn:88, tp:1450\n",
    "precision: 0.9415584415584416, recall: 0.9427828348504551, accuracy: 0.9412735070933685\n",
    "fraud_speaker字段指标:\n",
    "accuracy: 0.9168591224018475\n",
    "reason字段指标:\n",
    "precision: 0.44713901544014767, recall: 0.46087901443683615, f1-score: 0.4438610370678192\n",
    "CPU times: user 37min 5s, sys: 36.8 s, total: 37min 42s\n",
    "Wall time: 37min 13s\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc4538-b8f8-4ba1-a3cb-c182570e32b0",
   "metadata": {},
   "source": [
    "三个字段的评测指标分别如下：\n",
    "| 字段 | 指标  |\n",
    "| --- | --- |\n",
    "| is_fraud |  precision: 0.9415, recall: 0.9427, accuracy: 0.9412 |\n",
    "|fraud_speaker| accuracy: 0.9168 |\n",
    "|reason| precision: 0.4471, recall: 0.4608, f1-score: 0.4438 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e7fc12-0d65-42fd-987d-41762f51a20c",
   "metadata": {},
   "source": [
    "**小结**：本文通过引入K折交叉验证方法，循环选择不同的训练集和验证集进行多次迭代训练，将损失降到了一个更低的值，也在很大程度上缓解了[前面每次训练]过程中都出现的过拟合现象。最终在从未见过的测试数据集上进行评测时，精确率和召回率指标也有了一个大的提升，K折交叉验证这种方法确实能让模型对数据学习的更充分，最终得到的模型泛化能力也更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e90eb-495c-49fd-b1ab-d4372b3fa485",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "- [交叉验证方法汇总](https://blog.csdn.net/WHYbeHERE/article/details/108192957)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
