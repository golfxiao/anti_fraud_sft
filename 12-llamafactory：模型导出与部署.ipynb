{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f3d566-772d-4a7e-bfcb-d4eb79c7b846",
   "metadata": {},
   "source": [
    "## 模型导出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb89b2-ac82-4078-934f-d172b1ac7689",
   "metadata": {},
   "source": [
    "使用LoRA 适配器训练好模型后，每次推理时候都需要分别加载基座模型和 LoRA 适配器，一方面比较繁琐，另一方面也不利于模型部署，因此有必要将基座模型和 LoRA 适配器进行合并，导出成一个模型。\n",
    "\n",
    "LLamaFactory中自带模型合并的功能，只需要从`examples/merge_lora/llama3_lora_sft.yaml`拷贝一份配置根据自己的情况进行修改。修改后的配置文件示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35232e1-1506-4ccd-a7a6-e09e4f84a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Note: DO NOT use quantized model or quantization_bit when merging lora adapters\n",
      "\n",
      "### model\n",
      "model_name_or_path: /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\n",
      "adapter_name_or_path: /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0826/checkpoint-1400\n",
      "template: qwen\n",
      "finetuning_type: lora\n",
      "\n",
      "### export\n",
      "export_dir: /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0\n",
      "export_size: 2\n",
      "export_device: cuda\n",
      "export_legacy_format: false\n"
     ]
    }
   ],
   "source": [
    "!cat /data2/downloads/LLaMA-Factory/merge_qwen2_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b64bc-fd5b-4b2e-9989-4a2f499c9e3e",
   "metadata": {},
   "source": [
    "- export_size: 指定导出的模型文件分片大小，单位为GB, 适用于模型比较大需要分片导出的场景，以便在内存限制的设备上加载。\n",
    "- export_device: 导出模型时使用的设备。可以选择 cpu 或 cuda（即 GPU）。如果有强大的 GPU 可以使用，选择 cuda 可以加快导出速度。\n",
    "- export_legacy_format: 指定是否使用旧格式导出模型。通常情况下，选择 false 以导出使用最新格式的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5517b29-0360-452d-af03-34cf73c2cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "使用`llamafactory-cli`执行export命令导出模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd890d7-021e-4f4d-a4c4-a83eab31980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-29 11:25:38,878] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "WARNING 08-29 11:25:40 _custom_ops.py:14] Failed to import from vllm._C with ImportError('/data2/anaconda3/envs/python3_10/lib/python3.10/site-packages/vllm/_C.abi3.so: undefined symbol: _ZN5torch3jit11parseSchemaERKSs')\n",
      "[INFO|tokenization_utils_base.py:2287] 2024-08-29 11:25:43,766 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2287] 2024-08-29 11:25:43,766 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2287] 2024-08-29 11:25:43,766 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2287] 2024-08-29 11:25:43,766 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2287] 2024-08-29 11:25:43,766 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2287] 2024-08-29 11:25:43,766 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2533] 2024-08-29 11:25:44,032 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "08/29/2024 11:25:44 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
      "[INFO|configuration_utils.py:731] 2024-08-29 11:25:44,033 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-08-29 11:25:44,034 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.43.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "08/29/2024 11:25:44 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n",
      "[INFO|modeling_utils.py:3631] 2024-08-29 11:25:44,064 >> loading weights file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/model.safetensors\n",
      "[INFO|modeling_utils.py:1572] 2024-08-29 11:25:44,076 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1038] 2024-08-29 11:25:44,078 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4463] 2024-08-29 11:27:10,729 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4471] 2024-08-29 11:27:10,729 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:991] 2024-08-29 11:27:10,732 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/generation_config.json\n",
      "[INFO|configuration_utils.py:1038] 2024-08-29 11:27:10,732 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "08/29/2024 11:30:02 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "08/29/2024 11:30:08 - INFO - llamafactory.model.adapter - Merged 1 adapter(s).\n",
      "08/29/2024 11:30:08 - INFO - llamafactory.model.adapter - Loaded adapter(s): /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0826/checkpoint-1400\n",
      "08/29/2024 11:30:08 - INFO - llamafactory.model.loader - all params: 1,543,714,304\n",
      "08/29/2024 11:30:08 - INFO - llamafactory.train.tuner - Convert model dtype to: torch.bfloat16.\n",
      "[INFO|configuration_utils.py:472] 2024-08-29 11:30:09,181 >> Configuration saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/config.json\n",
      "[INFO|configuration_utils.py:807] 2024-08-29 11:30:09,182 >> Configuration saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/generation_config.json\n",
      "[INFO|modeling_utils.py:2763] 2024-08-29 11:30:13,625 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2702] 2024-08-29 11:30:13,626 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2711] 2024-08-29 11:30:13,626 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli export /data2/downloads/LLaMA-Factory/merge_qwen2_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b05bac-e2da-401d-afe4-1486760380e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "查看导出的模型文件，可以看到已经按照我们的配置将模型参数进行了两个分片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5a8d39-4c40-466c-888a-4ade0c3647b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3026368\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua         80 Aug 29 11:30 added_tokens.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua        748 Aug 29 11:30 config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua        242 Aug 29 11:30 generation_config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    1671853 Aug 29 11:30 merges.txt\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua 1975314632 Aug 29 11:30 model-00001-of-00002.safetensors\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua 1112152304 Aug 29 11:30 model-00002-of-00002.safetensors\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua      27693 Aug 29 11:30 model.safetensors.index.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua        367 Aug 29 11:30 special_tokens_map.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua       1532 Aug 29 11:30 tokenizer_config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    7028043 Aug 29 11:30 tokenizer.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    2776833 Aug 29 11:30 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd78084a-1c60-4334-90cf-b4b34b051e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3026356\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua        660 Aug  1 15:58 config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua         48 Aug  1 15:58 configuration.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua        242 Aug  1 15:58 generation_config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua      11344 Aug  1 15:58 LICENSE\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    1671839 Aug  1 15:58 merges.txt\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua 3087467144 Aug  1 16:16 model.safetensors\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua       3551 Aug  1 16:17 README.md\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua       1287 Aug  1 16:17 tokenizer_config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    7028015 Aug  1 16:17 tokenizer.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    2776833 Aug  1 16:17 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479f96c-c9c9-4279-81f1-d28768c4be63",
   "metadata": {},
   "source": [
    "## 测试模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73ab9b-8921-40f1-8da0-d1a1b810be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run evaluate.py\n",
    "model_path = '/data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0'\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac5c172b-0cd4-4e56-a80b-94d57bfa3d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778cc81c30524851ae8b0c3a122beda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run in batch mode, batch_size=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2348/2348 [01:58<00:00, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1162, fp:3, fn:70, tp:1113\n",
      "precision: 0.9973118279569892, recall: 0.9408284023668639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testdata_path = '/data2/anti_fraud/dataset/eval0819.jsonl'\n",
    "evaluate(model_path, '', testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff8feef-f304-45f5-9ebf-58e80e24c176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d8d3d0dd4b44249ef53c3cd48d9f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run in batch mode, batch_size=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [01:56<00:00, 20.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1136, fp:31, fn:162, tp:1020\n",
      "precision: 0.9705042816365367, recall: 0.8629441624365483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testdata_path = '/data2/anti_fraud/dataset/test0819.jsonl'\n",
    "evaluate(model_path, '', testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abab76d-04a4-4162-b03b-f1412b67d369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a026421e-2734-400e-b241-aba973f6b868",
   "metadata": {},
   "source": [
    "## 模型部署\n",
    "\n",
    "查看配置文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2ee93-2f13-414b-83d8-e6c28d8f6444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name_or_path: /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0\n",
      "template: qwen\n",
      "infer_backend: vllm\n",
      "vllm_enforce_eager: true\n",
      "\u001b[7m/data2/downloads/LLaMA-Factory/qwen2_inference.yaml (END)\u001b[m\u001b[K"
     ]
    }
   ],
   "source": [
    "!less /data2/downloads/LLaMA-Factory/qwen2_inference.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973fe0d5-b16c-4149-b5db-51ee1b35fbfd",
   "metadata": {},
   "source": [
    "通过llamafactory启动推理服务的方式：\n",
    "```\n",
    "llamafactory-cli api /data2/downloads/LLaMA-Factory/qwen2_inference.yaml\n",
    "```\n",
    "为了收集日志及指定环境变量，封装为一个启动脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e7ecb-d56f-40d6-a9fd-43b97b2331e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!less ~/anti_fraud_start.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5549a4-8f71-4e88-8f60-a1aae247aaee",
   "metadata": {},
   "source": [
    "启动服务后，使用openai的api来测试服务功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89561102-f44e-4605-aa82-03a0cb837bca",
   "metadata": {},
   "source": [
    "## 推理测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c2a80-8455-4008-b02a-316700062536",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# api_call_example.py\n",
    "from openai import OpenAI\n",
    "\n",
    "def predict(prompt):\n",
    "    client = OpenAI(api_key=\"0\",base_url=\"http://192.168.31.200:8001/v1\")\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    result = client.chat.completions.create(messages=messages, model=\"Qwen2-1__5B-Instruct\")\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "predict(\"详细介绍下你自己。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15927322-62a4-450d-a613-29174c560048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fraud_prompt(content):\n",
    "    return f\"下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true\\/false)。\\n{content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a1d0e2-ed1a-4c44-84c3-1aa5ef2dcb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 ms, sys: 3.71 ms, total: 57 ms\n",
      "Wall time: 217 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"is_fraud\": true}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "content = '小明: 我们有专业的团队进行风险管理，可以确保你的投资安全。而且我们会提供实时的投资动态，让你随时掌握投资情况。\\n小红: 那我什么时候能回收投资并获得收益呢？\\n小明: 投资期限为1年，到期后你就可以回收本金和收益。\\n小红: 听起来还不错，我会考虑一下。谢谢你的介绍。\\n小明: 不客气，如果你有任何问题，随时可以问我。希望你能抓住这个机会，获得更多的财富。'\n",
    "predict(build_fraud_prompt(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd62d178-5875-47b9-9244-018b2a1c0b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.9 ms, sys: 3.34 ms, total: 56.2 ms\n",
      "Wall time: 215 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"is_fraud\": false}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "content = '发言人3: 然后从不管是分业务板块的一个营收占比和分地区板块的或分地区的一个营收占比来看的话，首先这个屠宰基本上是占了公司总体营收的90%以上的一个比例，但是我们可以看到左下角的这个图，近几年畜禽养殖板块其实更多就来自于生猪养殖板块，它对于整个营收的一个占比它其实有一个明显的提升，而且随着未来公司出栏量的一个增长，包括可能猪价的一个后面有一个周期的一个反转的话，可能未来养殖板块它占总营收的一个比例仍然会有一个快速的一个提升。'\n",
    "predict(build_fraud_prompt(content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
