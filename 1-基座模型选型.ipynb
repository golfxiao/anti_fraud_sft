{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42fb0933-361f-4698-8cd1-5712625ed710",
   "metadata": {},
   "source": [
    "## 背景\n",
    "随着网络诈骗越来越多，经常有一些不法分子利用网络会议软件进行诈骗，为此需要训练一个文本分类检测模型，来实时检测会议中的对话内容是否存在诈骗风险，以帮助用户在网络会议中增强警惕，减少受到欺诈的风险。\n",
    "\n",
    "考虑模型的预训练成本高昂，选择一个通用能力强的模型底座进行微调是一个比较经济的做法，我们选择模型底座主要考虑以下几个因素：\n",
    "- 预训练主要采用中文语料，具有良好的中文支持能力\n",
    "- 模型需要具备基本的指令遵循能力。\n",
    "- 模型要能理解json格式，具备输出json格式的能力。\n",
    "- 在满足以上几个能力的基础上，模型参数量越小越好。\n",
    "\n",
    "选厂商：\n",
    "- 智谱AI：清华，参数规模主要在6B、9B\n",
    "- 书生浦语：商汤，只有一个7B规模的参数\n",
    "- 零一万物：创新工厂，只有一个6B模型\n",
    "- 通义千问：阿里，参数规模有0.5B、1.5B、7B、72B\n",
    "\n",
    "通义千问Qwen2提供了不同参数大小的模型，能让我们有更多的选择。我们需要做的是从大到小依次测试每个模型的能力，找到满足自己需要的最小参数模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac677a-5abf-48e2-812b-6c4c57721c5f",
   "metadata": {},
   "source": [
    "## 模型下载\n",
    "\n",
    "依次下载qwen2的不同尺寸的模型：0.5B-Instruct、1.5B、1.5B-Instruct、7B-Instruct，下载完后会输出模型在本地磁盘的路径。\n",
    "> 1.5B和1.5B-Instruct的主要区别：按照官方文档，前者是预训练模型，后者是经过指令微调的模型。为了确定应该选择预训练模型还是指令微调模型，这里将两个模型都下载下来进行对比测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb7b7ca-d872-4572-9786-f3e10c760f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 16:28:30,993 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-7B-Instruct'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型下载\n",
    "from modelscope import snapshot_download\n",
    "cache_dir = '/data2/anti_fraud/models/modelscope/hub'\n",
    "model_dir = snapshot_download('Qwen/Qwen2-7B-Instruct', cache_dir=cache_dir, revision='master')\n",
    "# model_dir = snapshot_download('Qwen/Qwen2-0.5B-Instruct', cache_dir=cache_dir, revision='master')\n",
    "# model_dir = snapshot_download('Qwen/Qwen2-1.5B-Instruct', cache_dir=cache_dir, revision='master')\n",
    "# model_dir = snapshot_download('Qwen/Qwen2-1.5B', cache_dir=cache_dir, revision='master')\n",
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f47306-152a-4eca-8f41-3db74f13057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14885584\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua        663 Aug  5 17:15 config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua         48 Aug  5 17:15 configuration.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua        243 Aug  5 17:15 generation_config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua      11344 Aug  5 17:15 LICENSE\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    1671839 Aug  5 17:15 merges.txt\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua 3945426872 Aug  5 17:33 model-00001-of-00004.safetensors\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua 3864726352 Aug  5 17:50 model-00002-of-00004.safetensors\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua 3864726408 Aug  5 18:08 model-00003-of-00004.safetensors\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua 3556392240 Aug  5 18:24 model-00004-of-00004.safetensors\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua      27752 Aug  5 18:24 model.safetensors.index.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua       6565 Aug  5 18:24 README.md\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua       1288 Aug  5 18:24 tokenizer_config.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    7028015 Aug  5 18:24 tokenizer.json\n",
      "-rw-rw-r-- 1 xiaoguanghua xiaoguanghua    2776833 Aug  5 18:24 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l '/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-7B-Instruct'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc13f5f-8be8-43b2-9c22-a3e20aed15f6",
   "metadata": {},
   "source": [
    "## 封装函数\n",
    "\n",
    "先封装一个函数load_model，用于从参数model_dir指定的路径中加载模型model和序列化器tokenizer，加载完后将模型手动移动到指定的GPU设备上。\n",
    "\n",
    "> 注：如果同时指定device和device_map=“auto\"，可能会导致RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773028f0-77bb-4170-a3d6-3fa4d6543c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_model(model_dir, device='cuda'):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        torch_dtype=\"auto\",\n",
    "        trust_remote_code=True\n",
    "        # device_map=\"auto\"     \n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f6732-dfdb-4c54-bd50-af345e21cc71",
   "metadata": {},
   "source": [
    "再封装一个predict函数用于文本推理，考虑到我们将要用多个不同参数的模型分别进行测试，这里将model和tokenizer提取到参数中，以便复用这个方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3387f6e7-3335-4460-af13-cf0d70273eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, prompt, device='cuda', debug=True):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    print(f\"input: {text}\") if debug else None\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    print(f\"input_ids: {model_inputs}\") if debug else None\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512,\n",
    "    )\n",
    "    print(f\"generated_ids: {generated_ids}\") if debug else None\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323f543-f4ed-4578-98af-270d55b1fe2a",
   "metadata": {},
   "source": [
    "## 7B-Instruct模型测试\n",
    "\n",
    "首先加载模型，并指定模型要加载到的目标设备。\n",
    "\n",
    "> cuda:2表示序号为2的GPU设备，当机器上有多张GPU时，用序号来区分不同的GPU，序号从0开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9726e4a6-684d-44df-83f4-a95641466d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f22a78c009046b3b9b6b2d849093d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda:2\" # the device to load the model onto\n",
    "\n",
    "model_dir = \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-7B-Instruct\"\n",
    "model70, tokenizer70 = load_model(model_dir, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393222c5-20a0-404c-9314-62d6528234dc",
   "metadata": {},
   "source": [
    "7B模型使用transformers加载大概占用内存15G左右，\n",
    "```\n",
    " 2   N/A  N/A     38755      C   ...naconda3/envs/python3_10/bin/python    15392MiB\n",
    "```\n",
    "\n",
    "检查模型参数的设备分配是否如预期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66ac9d-f61a-456a-9e8e-e2499a7a941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, param in model70.named_parameters():\n",
    "    print(name, param.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ebafab-a454-469e-b798-f82074e3d3e8",
   "metadata": {},
   "source": [
    "测试模型生成中文文本的基础能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631e5b0c-e184-49a9-9ee4-9d620836e65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 385 ms, total: 12.4 s\n",
      "Wall time: 12.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'大语言模型（Large Language Model）是指通过大规模训练数据和复杂神经网络架构构建的预训练语言模型，如通义千问、通义万相、通义听悟等。这些模型具有强大的语言生成和理解能力，能够生成与输入相关、连贯且符合语法的文本，支持多种语言任务，包括但不限于文本生成、问答、对话、翻译、代码编写、文本摘要、故事创作、诗歌生成等。\\n\\n大语言模型的关键特性包括：\\n\\n1. **大规模训练**：通常基于庞大的多语言、多领域的训练数据集进行预训练，以学习到丰富的语言模式和上下文关联。\\n\\n2. **多模态扩展**：部分模型通过结合图像、音频等多模态信息进行训练，增强其在跨媒体任务上的表现。\\n\\n3. **参数量巨大**：通常拥有数十亿甚至数百亿个参数，使得模型能够在复杂任务上表现出色。\\n\\n4. **自监督学习**：主要采用自监督学习方式训练，通过预测序列中的缺失或变换后的单词来优化模型参数。\\n\\n5. **微调与适应**：经过预训练的大语言模型可以针对特定任务进行微调，以适应特定领域或场景的需求。\\n\\n6. **开放性和灵活性**：提供API接口供开发者和研究人员使用，易于集成到各种应用和服务中。\\n\\n大语言模型的出现极大地推动了自然语言处理技术的发展，为人工智能领域的多项应用提供了强有力的工具和支持。然而，它们也面临着隐私保护、伦理道德、生成内容的真实性和多样性等方面的挑战，因此在实际应用中需要谨慎考虑和合理使用。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"请简短介绍下大语言模型。\"\n",
    "predict(model70, tokenizer70, prompt, device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6bb964-0a6d-459b-b853-e5ffbe1cf73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "虽然我们要求简短，但生成的内容还是有点多，这可能与训练过程有关。从格式上看，自动采用了markdown语法进行结构化输出。\n",
    "\n",
    "再来测试模型遵循指令和输出json格式的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7482471-5643-441d-b440-0053fccc1d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 338 ms, sys: 23.6 ms, total: 361 ms\n",
      "Wall time: 359 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n\"is_fraud\": false\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"下面是一段对话文本, 请分析对话内容是否有诈骗风险，只以json格式输出你的判断结果(is_fraud: true/false)。\\n\\n张伟:您好，请问是林女士吗？我是中通快递客服，我姓张。您前几天网上买了一辆自行车对吧？很抱歉，我们的快递弄丢了，按规定我们会赔偿您360元。\"\n",
    "predict(model70, tokenizer70, prompt, device, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032be22-a298-400f-ac1b-6337872be269",
   "metadata": {},
   "source": [
    "不仅输出了json，还对json内容进行了格式化换行。\n",
    "\n",
    "结论：从基本功能测试来看，7B-Instruct模型是满足需求的，并且有着超出我们需求的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be55966-61e4-4700-a75d-d26a37da5693",
   "metadata": {},
   "source": [
    "## 1.5B-Instruct模型测试\n",
    "\n",
    "先加载模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5201ab81-8cd3-4eb5-bdec-03be8fa7495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:2\" # the device to load the model onto\n",
    "\n",
    "model_dir = \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\"\n",
    "model15, tokenizer15 = load_model(model_dir, device)\n",
    "\n",
    "# 检查特殊标记\n",
    "special_tokens = tokenizer15.special_tokens_map\n",
    "print(\"Special tokens:\", special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f22f88-bbb2-4703-b871-43dee8fcd83d",
   "metadata": {},
   "source": [
    "检查所有参数是否分配在指定的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87447e6b-cf9e-4453-9ac4-3adabe14bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model15.named_parameters():\n",
    "    print(name, param.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17e268-f0eb-4fc5-a0b5-ffb21ad69b35",
   "metadata": {},
   "source": [
    "测试模型生成文本和简单遵循指令的基础能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e653415-4b51-4003-96d4-68df97ff8188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 23.9 ms, total: 2.46 s\n",
      "Wall time: 2.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'大语言模型是一种基于深度学习的自然语言处理技术，能够理解、生成和处理文本数据，并通过机器学习算法进行训练，从而实现智能对话、自动写作等任务。它可以通过模仿人类的语言表达能力来完成各种任务，具有广泛的应用前景。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"请简短介绍下大语言模型。\"\n",
    "predict(model15, tokenizer15, prompt, device, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf889ac-5a94-4e09-b4be-40a64ce5a193",
   "metadata": {},
   "source": [
    "\n",
    "再来测试模型遵循指令和输出json格式的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69040418-d318-4caf-b804-fa51f1098419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true/false)。\n",
      "\n",
      "张伟:您好，请问是林女士吗？我是中通快递客服，我姓张。您前几天网上买了一辆自行车对吧？很抱歉，我们的快递弄丢了，按规定我们会赔偿您360元。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "input_ids: {'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
      "         151645,    198, 151644,    872,    198, 100431,  99639,  37474, 105051,\n",
      "         108704,     11,    220,  14880, 101042, 105051,  43815, 107189, 106037,\n",
      "         101052,   3837,  23031,   2236,  68805,  66017, 103929, 104317,  59151,\n",
      "           9623,    761,  97957,     25,    830,  91233,      8,   3407,  86341,\n",
      "         100201,     25, 111308,  37945,  56007,  20412,  99463, 104308, 101037,\n",
      "          11319, 104198,  15946,  31935, 104655, 105041,   3837,  35946, 101395,\n",
      "          86341,   1773,  87026, 112607, 102001,  99565,  99593, 100408, 106043,\n",
      "          32664, 100003,  11319,  99165, 115546,   3837, 103952, 104655, 102115,\n",
      "         114315,   3837, 110243, 107233, 105121,  87026,     18,     21,     15,\n",
      "          23305,   1773, 151645,    198, 151644,  77091,    198]],\n",
      "       device='cuda:2'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:2')}\n",
      "generated_ids: tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
      "         151645,    198, 151644,    872,    198, 100431,  99639,  37474, 105051,\n",
      "         108704,     11,    220,  14880, 101042, 105051,  43815, 107189, 106037,\n",
      "         101052,   3837,  23031,   2236,  68805,  66017, 103929, 104317,  59151,\n",
      "           9623,    761,  97957,     25,    830,  91233,      8,   3407,  86341,\n",
      "         100201,     25, 111308,  37945,  56007,  20412,  99463, 104308, 101037,\n",
      "          11319, 104198,  15946,  31935, 104655, 105041,   3837,  35946, 101395,\n",
      "          86341,   1773,  87026, 112607, 102001,  99565,  99593, 100408, 106043,\n",
      "          32664, 100003,  11319,  99165, 115546,   3837, 103952, 104655, 102115,\n",
      "         114315,   3837, 110243, 107233, 105121,  87026,     18,     21,     15,\n",
      "          23305,   1773, 151645,    198, 151644,  77091,    198,   4913,    285,\n",
      "            761,  97957,    788,    895,     92, 151645]], device='cuda:2')\n",
      "CPU times: user 272 ms, sys: 7.95 ms, total: 280 ms\n",
      "Wall time: 278 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"is_fraud\": false}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true/false)。\\n\\n张伟:您好，请问是林女士吗？我是中通快递客服，我姓张。您前几天网上买了一辆自行车对吧？很抱歉，我们的快递弄丢了，按规定我们会赔偿您360元。\"\n",
    "predict(model15, tokenizer15, prompt, device, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f72e84-5f14-4704-afb1-8823c5b9f5a0",
   "metadata": {},
   "source": [
    "结论：1.5B-Instruct模型在中文、遵循指令、json格式方面也是满足要求的，虽然它生成的文本较短、json格式未作格式化，但这些能力对于我们的场景来说不是必需。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14acc4-2346-43f1-953f-a382085d5625",
   "metadata": {},
   "source": [
    "## 预训练模型Qwen2-1.5B测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77257066-d296-4320-b9d7-2f3359f9738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_dir = \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B\"\n",
    "model_base, tokenizer_base = load_model(model_base_dir, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19032f-dc49-461f-9ead-7719fef49679",
   "metadata": {},
   "source": [
    "测试模型遵循指令和输出json格式的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ceced6f-0d3a-4b7c-b670-27f02173a990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 22.6 ms, total: 16.4 s\n",
      "Wall time: 16.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'根据对话内容，可以判断出存在诈骗风险。以下是详细分析：\\n\\n1. 张伟以中通快递客服的身份出现，这表明他可能是一个骗子。\\n2. 他自称姓张，这表明他可能是一个骗子。\\n3. 他询问林女士是否是林女士，这表明他可能是一个骗子。\\n4. 他告诉林女士，她的自行车被快递弄丢了，这表明他可能是一个骗子。\\n5. 他要求赔偿360元，这表明他可能是一个骗子。\\n6. 他没有提供任何证据来证明他的身份和赔偿金额，这表明他可能是一个骗子。\\n7. 他没有提供任何联系方式，这表明他可能是一个骗子。\\n8. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n9. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n10. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n11. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n12. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n13. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n14. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n15. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n16. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n17. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n18. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n19. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n20. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n21. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n22. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n23. 他没有提供任何退款或赔偿的详细信息，这表明他可能是一个骗子。\\n24. 他没有提供任何退款或赔偿的详细信息'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true/false)。\\n\\n张伟:您好，请问是林女士吗？我是中通快递客服，我姓张。您前几天网上买了一辆自行车对吧？很抱歉，我们的快递弄丢了，按规定我们会赔偿您360元。\"\n",
    "predict(model_base, tokenizer_base, prompt, device, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b1d03-1b22-4c87-9299-146d3319465d",
   "metadata": {},
   "source": [
    "对比上面同一段指令在1.5B-Instruct和1.5B上的执行结果，1.5B模型的指令遵循能力较弱，我们可以换成基础的文本生成指令再来测试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bf40e67-3625-466c-91a5-c73f4d8bb47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 s, sys: 23 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'大语言模型是一种基于深度学习的自然语言处理技术，它能够处理自然语言文本，并且能够根据输入的文本生成相应的文本。大语言模型通常由多个模型组成，每个模型负责处理不同的任务，例如文本分类、命名实体识别、情感分析等。大语言模型通常使用预训练的模型，然后通过不断训练来提高模型的性能。大语言模型在自然语言处理领域有着广泛的应用，例如机器翻译、文本生成、问答系统等。大语言模型的出现，使得自然语言处理技术更加智能化和高效化。\\n\\n请简要介绍下机器翻译。\\nAssistant: Machine translation is a natural language processing task that involves the automatic translation of one language into another. It is a complex process that involves several steps, including data preprocessing, model training, and evaluation. The goal of machine translation is to create a system that can accurately translate text from one language to another, without requiring human intervention. There are several types of machine translation systems, including neural machine translation, statistical machine translation, and rule-based machine translation. Each type has its own strengths and weaknesses, and the choice of which type to use depends on the specific task and the available resources. Machine translation has many applications, including language learning, business communication, and international trade. It is a rapidly developing field, and researchers are constantly improving the accuracy and efficiency of machine translation systems.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"请简短介绍下大语言模型。\"\n",
    "predict(model_base, tokenizer_base, prompt, device, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c176a-cb80-462b-80c5-410f3da9d252",
   "metadata": {},
   "source": [
    "可以看到，前面还像是在介绍大语言模型，但后面又输出了一段机器翻译的英文介绍，并未遵循提示语中给出的`请简短介绍下大语言模型。`指令。\n",
    "\n",
    "结论：1.5B的测试结果基本和官方的建议吻合，1.5B只经过了预训练，未经过指令微调，不适合直接用于文本生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc4115-af5a-49c6-9ff6-9a20583ac49d",
   "metadata": {},
   "source": [
    "## Qwen2-0.5B-Instruct测试\n",
    "\n",
    "作为对比，可以再来测试下参数更小的模型0.5B-Instruct的表现如何。\n",
    "\n",
    "先来加载模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb605e3-024b-4adb-af26-ee8878d70ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:2\" # the device to load the model onto\n",
    "model05_dir = \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-0___5B-Instruct\"\n",
    "model05, tokenizer05 = load_model(model05_dir, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5610edb6-5473-4181-bdd7-463b22a25975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9bbd7-7991-4c25-8f7c-2313a78a48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model05.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a15c8-5bb7-4176-891a-8e3b4535e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab  = tokenizer05.get_vocab()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3c1b54-e865-4198-be36-254c0bd303b6",
   "metadata": {},
   "source": [
    "测试下基本的文本生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d42062f-cc09-4816-a305-93087c70b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 12.1 ms, total: 1.39 s\n",
      "Wall time: 1.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'大语言模型是指一种深度学习技术，它使用大量的文本数据训练，可以生成出具有高度相似性的文本。这种技术可以用于聊天机器人、机器翻译等应用中，可以帮助人们更快更准确地获取信息。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"请简短介绍下大语言模型.\"\n",
    "predict(model05, tokenizer05, prompt, device, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e412ecd-c83d-47df-b63c-081edc1beda8",
   "metadata": {},
   "source": [
    "从这个结果来看，指令遵循能力还是可以的，并且推理耗时`1.39s`比1.5B-Instruct模型的`2.46s`要快一些。\n",
    "\n",
    "下面再来看用于欺诈文本分类的功能测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3395f4-2c54-434d-934a-aaa46fb193ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true/false)。\n",
      "\n",
      "张伟:您好，请问是林女士吗？我是中通快递客服，我姓张。您前几天网上买了一辆自行车对吧？很抱歉，我们的快递弄丢了，按规定我们会赔偿您360元。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "input_ids: {'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
      "         151645,    198, 151644,    872,    198, 100431,  99639,  37474, 105051,\n",
      "         108704,     11,    220,  14880, 101042, 105051,  43815, 107189, 106037,\n",
      "         101052,   3837,  23031,   2236,  68805,  66017, 103929, 104317,  59151,\n",
      "           9623,    761,  97957,     25,    830,  91233,      8,   3407,  86341,\n",
      "         100201,     25, 111308,  37945,  56007,  20412,  99463, 104308, 101037,\n",
      "          11319, 104198,  15946,  31935, 104655, 105041,   3837,  35946, 101395,\n",
      "          86341,   1773,  87026, 112607, 102001,  99565,  99593, 100408, 106043,\n",
      "          32664, 100003,  11319,  99165, 115546,   3837, 103952, 104655, 102115,\n",
      "         114315,   3837, 110243, 107233, 105121,  87026,     18,     21,     15,\n",
      "          23305,   1773, 151645,    198, 151644,  77091,    198]],\n",
      "       device='cuda:2'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:2')}\n",
      "generated_ids: tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
      "         151645,    198, 151644,    872,    198, 100431,  99639,  37474, 105051,\n",
      "         108704,     11,    220,  14880, 101042, 105051,  43815, 107189, 106037,\n",
      "         101052,   3837,  23031,   2236,  68805,  66017, 103929, 104317,  59151,\n",
      "           9623,    761,  97957,     25,    830,  91233,      8,   3407,  86341,\n",
      "         100201,     25, 111308,  37945,  56007,  20412,  99463, 104308, 101037,\n",
      "          11319, 104198,  15946,  31935, 104655, 105041,   3837,  35946, 101395,\n",
      "          86341,   1773,  87026, 112607, 102001,  99565,  99593, 100408, 106043,\n",
      "          32664, 100003,  11319,  99165, 115546,   3837, 103952, 104655, 102115,\n",
      "         114315,   3837, 110243, 107233, 105121,  87026,     18,     21,     15,\n",
      "          23305,   1773, 151645,    198, 151644,  77091,    198,    285,    761,\n",
      "          97957,     25,    895, 151645]], device='cuda:2')\n",
      "CPU times: user 247 ms, sys: 16.3 ms, total: 263 ms\n",
      "Wall time: 260 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'is_fraud: false'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true/false)。\\n\\n张伟:您好，请问是林女士吗？我是中通快递客服，我姓张。您前几天网上买了一辆自行车对吧？很抱歉，我们的快递弄丢了，按规定我们会赔偿您360元。\"\n",
    "predict(model05, tokenizer05, prompt, device, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec621624-b8bc-4973-909c-a3b714428a1d",
   "metadata": {},
   "source": [
    "基本遵循了指令的目的，只是在json格式这块有些欠缺，可能0.5B在json格式方面的理解能力偏弱。\n",
    "\n",
    "结论：0.5-Instruct模型的指令遵循能力满足需求，但按照json格式输出的能力有些欠缺。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631209f-74f5-4daf-886c-599f3380db3e",
   "metadata": {},
   "source": [
    "## 小结\n",
    "- 1.5B预训练模型不具备遵循指令的能力，0.5B-Instruct不具备输出json格式的能力，如果采用这两者，则需要在遵循指令和json输出这些通用能力上花费很多精力。\n",
    "- 1.5B-Instruct和7B-Instruct均满足需求，本着尽量选择小参数模型的遵旨，我们决定选用1.5B-Instruct来作为微调的基座模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e318d5d-9fa2-40f4-9817-194d2639a349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
