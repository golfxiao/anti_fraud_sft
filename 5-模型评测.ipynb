{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618092e3-00e1-4cb2-89fb-7e58edd3c2f6",
   "metadata": {},
   "source": [
    "## 引言\n",
    "前面一篇文章[欺诈文本分类微调（四）：构造训练/测试数据集](https://golfxiao.blog.csdn.net/article/details/141325192)已经构造出了测试数据集，这篇文章将基于测试数据集做模型评测，由于还没有开始训练，所以先对基座模型做评测。\n",
    "\n",
    "我们的任务目标是对文本进行分类，所以评测的目标是计算模型的精确率和召回率。评测的过程大概是：\n",
    "1. 用目标模型对每条数据的input做推理，得到一个预测值。\n",
    "2. 收集所有数据的预测值和标签值，并比较预测正确和预测错误的数量。\n",
    "3. 根据比较结果计算模型的精确率和召回率。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe90d1-2c85-4c2d-a434-aed796816367",
   "metadata": {},
   "source": [
    "## 准备数据和模型\n",
    "\n",
    "先导入需要用到的库，其中：\n",
    "- transformers用于加载原始模型\n",
    "- peft用于加载微调模型\n",
    "- sklearn.metrics用于计算精确率和召回率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "094b7106-96e6-4114-b69c-4425e795f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import *\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af9952-d0ec-4c50-8732-0c4ce7bc2acc",
   "metadata": {},
   "source": [
    "定义评估数据集所在文件路径，以及原始模型路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dce413-bd28-450f-82d8-1d4d9a2ea35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_path = '/data2/anti_fraud/dataset/eval0819.jsonl'\n",
    "model_path = '/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea705f3b-e606-4224-b375-4dd79205aac1",
   "metadata": {},
   "source": [
    "#### 加载数据\n",
    "\n",
    "上面定义的评估数据集采用jsonl格式保存，所以需要一个方法来加载jsonl格式的数据集，本质上就是用json.loads分别加载每条数据，最后再组成一个list。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e17f52-af13-432c-a746-4c3aaf905015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "        return data\n",
    "\n",
    "test_data = load_jsonl(testdata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ceff2c-801d-4337-82d5-32ed2e2b9f13",
   "metadata": {},
   "source": [
    "查看下数据集是否均衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec311a3-bd49-4c84-b04d-69b18e1f5e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count: 2348, true_data: 1183, false_data: 1165\n"
     ]
    }
   ],
   "source": [
    "true_data = [d for d in test_data if d['label'] == True]\n",
    "false_data = [d for d in test_data if d['label'] == False]\n",
    "print(f\"total_count: {len(test_data)}, true_data: {len(true_data)}, false_data: {len(false_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21311e-0aee-448e-ad4b-e74e6f5578f6",
   "metadata": {},
   "source": [
    "#### 加载模型\n",
    "定义一个方法load_model来同时支持加载原始模型和微调后的模型，使用时的区别在于是否传参微调后的checkpoint_path。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a6d5b0-b845-4bf0-8805-344bf5f433b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, checkpoint_path='', device='cuda'):\n",
    "    # 加载tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, padding_side=\"left\")\n",
    "    # 加载模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, trust_remote_code=True).eval().to(device)\n",
    "    # 加载lora权重\n",
    "    if checkpoint_path: \n",
    "        model = PeftModel.from_pretrained(model, model_id=checkpoint_path).to(device)\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50359c1d-5b0d-4b3a-a1f8-36e096bc8da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = load_model(model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95522ab8-1cd7-4291-bac9-5932510a4094",
   "metadata": {},
   "source": [
    "定义一个推理函数predict，用传入的模型和一条对话文本来进行欺诈文本分类的推理。此函数定义时要考虑以下几点：\n",
    "1. 既要测试原始模型，也要测试微调后的模型，并且可能会微调多个版本，所以把model和tokenizer作为参数传入。\n",
    "2. 由于模型预测结果的不确定性，在使用json加载解析response时可能会报异常，需要加一个safe_loads保护。\n",
    "\n",
    "> 注：语言模型在生成json时，很容易输出markdown文本中嵌入的json格式，所以在解析json之前先尝试去除markdown代码块的头和尾。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ce2e34-771a-4e16-990b-08ea45d4a11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_fraud': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safe_loads(text, default_value=None):\n",
    "    json_string = re.sub(r'^```json\\n(.*)\\n```$', r'\\1', text.strip(), flags=re.DOTALL)\n",
    "    try:  \n",
    "        return json.loads(json_string)  \n",
    "    except json.JSONDecodeError as e:  \n",
    "        print(f\"invalid json: {json_string}\")\n",
    "        return default_value  \n",
    "\n",
    "def predict(model, tokenizer, content, device='cuda', debug=False):\n",
    "    prompt = f\"下面是一段对话文本, 请分析对话内容是否有诈骗风险，只以json格式输出你的判断结果(is_fraud: true/false)。\\n\\n{content}\"\n",
    "    inputs = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}],\n",
    "                                           add_generation_prompt=True,\n",
    "                                           tokenize=True,\n",
    "                                           return_tensors=\"pt\",\n",
    "                                           return_dict=True\n",
    "                                           ).to(device)\n",
    "    \n",
    "    print(f\"inputs.shape: {inputs['input_ids'].shape[1]}\") if debug else None\n",
    "    default_response = {'is_fraud':False}\n",
    "    gen_kwargs = {\"max_new_tokens\": 2048, \"do_sample\": True, \"top_k\": 1}\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **gen_kwargs)\n",
    "        print(f\"outputs.shape: {outputs.shape}\") if debug else None\n",
    "        outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return safe_loads(response, default_response)\n",
    "\n",
    "predict(model, tokenizer, '郎艳: 最近找到了一条新的货源，在重庆那边，如果您愿意投资，可以以很低的价格买到衣服，并且出租赚钱哦。投资金额500元到10000元不等，非常划算的。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada37f4-34a6-4fc7-9eff-391639cc326d",
   "metadata": {},
   "source": [
    "#### 评测方法\n",
    "\n",
    "评测主要是对所有数据的预测结果进行是否正确的统计与分析，最终根据自己的侧重点来计算出一两个指标用于评估模型性能。\n",
    "\n",
    "首先定义一个方法，对所有的test_data来进行分类预测，并返回所有数据的真实标签和预测标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b518db3b-e8c8-4a78-a9ed-24e10ecc266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(model, tokenizer, test_data, device='cuda', debug=False):\n",
    "    real_labels = []\n",
    "    pred_labels = []\n",
    "    pbar = tqdm(total=len(test_data), desc=f'progress')\n",
    "    \n",
    "    for i, item in enumerate(test_data):\n",
    "        dialog_input = item['input']\n",
    "        real_label = item['label']\n",
    "        \n",
    "        prediction = predict(model, tokenizer, dialog_input, device)\n",
    "        pred_label = prediction['is_fraud']\n",
    "        \n",
    "        real_labels.append(real_label)\n",
    "        pred_labels.append(pred_label)\n",
    "        \n",
    "        pbar.update()\n",
    "        # print(f\"percent: {(i*100)/len(test_data):.2f}%\") if (debug and i%(len(test_data)//20 + 1)==0) else None\n",
    "    return real_labels, pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090af225-d553-4c35-8647-61cffee0b76d",
   "metadata": {},
   "source": [
    "用一个迷你数据集（只有10条数据）来测试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f05ba61b-3e17-4889-a339-312697846977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 10/10 [00:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([False, False, False, True, True, False, True, True, False, False],\n",
       " [True, False, False, False, False, False, False, True, False, False])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels, pred_labels = run_test(model, tokenizer, test_data[:10], debug=True)\n",
    "real_labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a67ea-042f-46d9-b030-22e919504f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "对于二分类问题，常用的评测指标是计算精确率和召回率。\n",
    "\n",
    "定义计算召回率和精确率的方法，相关方法和概念解释如下：\n",
    "- confusion_matrix函数接受一个标签分类值集合和预测分类值集合，返回一个2x2的矩阵包含4个数据，分别是真负、假正、假负、真正的统计数字。\n",
    "- precision:精确率，表示预测为正的结果中有多少是真的正值，计算公式为：精确率=真正/(真正+假正）\n",
    "- recall：召回率，表示标签中为正的数据有多少被成功预测召回，计算公式为：召回率=真正/(真正+假负）                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a1cfa03-6620-4a8b-ac2e-3c329a292bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1, fp:3, fn:1, tp:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.625, 0.8333333333333334)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_recall(true_labels, pred_labels, labels=None, debug=False):\n",
    "    cm = confusion_matrix(true_labels, pred_labels, labels=labels)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"tn：{tn}, fp:{fp}, fn:{fn}, tp:{tp}\") if debug else None\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return precision, recall\n",
    "\n",
    "precision_recall(real_labels, pred_labels, labels=[True, False], debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ead04-91bf-4987-900c-e43b087087c3",
   "metadata": {},
   "source": [
    "> 上面的(0.625, 0.833)就是模型在上面10条数据上计算出的精确率和召回率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8c274-bc10-490b-be36-0004318525f8",
   "metadata": {},
   "source": [
    "## 运行评测\n",
    "\n",
    "将上面的步骤封装到一个evaluate方法中，这样只需要一句代码就能运行评估并输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5f1714e-cda0-4bb5-abfe-7be6942c5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_path, checkpoint_path, dataset, device='cuda', debug=False):\n",
    "    model, tokenizer = load_model(model_path, checkpoint_path, device)\n",
    "    true_labels, pred_labels = run_test(model, tokenizer, dataset, device, debug=debug)\n",
    "    precision, recall = precision_recall(true_labels, pred_labels, debug=debug)\n",
    "    print(f\"precision: {precision}, recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f67a5-350f-4a90-b524-7ce9771cb11c",
   "metadata": {},
   "source": [
    "计算原始模型的精确率和召回率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8537987e-24f5-4ea7-95d1-75707bd6900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900e70f-85c9-48a5-9e83-1fc810594db2",
   "metadata": {},
   "source": [
    "#### 原始模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f890ff2a-117b-4766-b1f1-b20c55d6bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:   5%|▌         | 123/2348 [00:43<31:42,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 很抱歉，由于我无法直接查看或访问任何外部数据集，因此无法分析对话内容是否包含欺诈行为。我的功能仅限于回答一般性问题和提供信息。如果您有其他相关的问题，请随时提问。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:   8%|▊         | 191/2348 [01:06<16:34,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 很抱歉，由于我无法直接查看或处理文件，请提供具体的对话文本。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:  80%|███████▉  | 1874/2348 [08:22<05:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 很抱歉，由于我无法直接查看或访问任何外部数据集，因此无法分析对话内容是否包含欺诈行为。我的功能仅限于回答一般性问题和提供信息。如果您有其他相关的问题，请随时提问。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2348/2348 [10:24<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1095, fp:70, fn:644, tp:539\n",
      "precision: 0.8850574712643678, recall: 0.4556213017751479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model_path, '', test_data, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960e6b8-09e6-4f4c-a29c-f45ceabb1f2d",
   "metadata": {},
   "source": [
    "## 封装脚本\n",
    "由于模型微调往往要反复调参进行训练，每次训练完都需要用上面的过程来评测模型的精确率和召回率指标，所以有必要将上面的评测过程封装为一个`evaluate.py`，以方便使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef390f27-c6a1-4ec5-ab83-ed6335fcea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "from tqdm import *\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "def load_jsonl(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "        return data\n",
    "\n",
    "def load_model(model_path, checkpoint_path='', device='cuda'):\n",
    "    # 加载tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    # 加载模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, trust_remote_code=True).eval().to(device)\n",
    "    # 加载lora权重\n",
    "    if checkpoint_path: \n",
    "        model = PeftModel.from_pretrained(model, model_id=checkpoint_path).to(device)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def safe_loads(text, default_value=None):\n",
    "    json_string = re.sub(r'^```json\\n(.*)\\n```$', r'\\1', text.strip(), flags=re.DOTALL)\n",
    "    try:  \n",
    "        return json.loads(json_string)  \n",
    "    except json.JSONDecodeError as e:  \n",
    "        print(f\"invalid json: {json_string}\")\n",
    "        return default_value  \n",
    "\n",
    "def predict(model, tokenizer, content, device='cuda', debug=False):\n",
    "    prompt = f\"下面是一段对话文本, 请分析对话内容是否有诈骗风险，只以json格式输出你的判断结果(is_fraud: true/false)。\\n\\n{content}\"\n",
    "    inputs = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}],\n",
    "                                           add_generation_prompt=True,\n",
    "                                           tokenize=True,\n",
    "                                           return_tensors=\"pt\",\n",
    "                                           return_dict=True\n",
    "                                           ).to(device)\n",
    "    \n",
    "    default_response = {'is_fraud':False}\n",
    "    gen_kwargs = {\"max_new_tokens\": 2048, \"do_sample\": True, \"top_k\": 1}\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **gen_kwargs)\n",
    "        outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return safe_loads(response, default_response)\n",
    "\n",
    "def run_test(model, tokenizer, test_data, device='cuda', debug=False):\n",
    "    real_labels = []\n",
    "    pred_labels = []\n",
    "    pbar = tqdm(total=len(test_data), desc=f'progress')\n",
    "    for i, item in enumerate(test_data):\n",
    "        dialog_input = item['input']\n",
    "        real_label = item['label']\n",
    "        \n",
    "        prediction = predict(model, tokenizer, dialog_input, device)\n",
    "        pred_label = prediction['is_fraud']\n",
    "        \n",
    "        real_labels.append(real_label)\n",
    "        pred_labels.append(pred_label)\n",
    "        pbar.update(1)\n",
    "    return real_labels, pred_labels\n",
    "\n",
    "def precision_recall(true_labels, pred_labels, labels=None, debug=False):\n",
    "    cm = confusion_matrix(true_labels, pred_labels, labels=labels)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"tn：{tn}, fp:{fp}, fn:{fn}, tp:{tp}\") if debug else None\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return precision, recall\n",
    "\n",
    "def evaluate_with_model(model, tokenizer, testdata_path, device='cuda', debug=False):\n",
    "    dataset = load_jsonl(testdata_path)\n",
    "    run_test_func = run_test_batch if batch else run_test\n",
    "    true_labels, pred_labels = run_test_func(model, tokenizer, dataset, device=device, debug=debug)\n",
    "    precision, recall = precision_recall(true_labels, pred_labels, debug=debug)\n",
    "    print(f\"precision: {precision}, recall: {recall}\")\n",
    "\n",
    "def evaluate(model_path, checkpoint_path, testdata_path, device='cuda', debug=False):    \n",
    "    model, tokenizer = load_model(model_path, checkpoint_path, device)\n",
    "    evaluate_with_model(model, tokenizer, testdata_path, device, batch, debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5b6b9-982e-47ea-bf4f-c22b237bc3cc",
   "metadata": {},
   "source": [
    "#### 7B模型评测对比\n",
    "\n",
    "使用此脚本对Qwen2-7B模型的评测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e222713-3907-44b9-9468-4f2d17274fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef3f251d1bc4ee6912f7d9246828bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run in batch mode, batch_size=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:   5%|████▏                                                                                    | 112/2348 [00:20<12:40,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的判断，我需要更多的上下文信息来分析这段对话。仅凭“发言人3: 明白”这一句话，很难判断是否存在诈骗风险。通常在分析对话时，会考虑对话中的具体语境、涉及的交易细节、请求或提供的信息类型等因素。例如，如果在这之前有提到某个具体的交易、投资机会、汇款请求等，并且这些内容存在不寻常、可疑或可能误导的情况，那么这句“明白”可能会被看作是潜在诈骗的一部分。\n",
      "\n",
      "由于没有足够的上下文信息，我无法准确判断这段对话是否包含诈骗风险。因此，基于当前的信息，我将答案设置为：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": null\n",
      "}\n",
      "```\n",
      "\n",
      "这意味着根据提供的信息，无法确定是否存在诈骗风险。如果有更多的对话内容或者更详细的背景信息，请提供以便进行更准确的分析。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:   5%|████▊                                                                                    | 128/2348 [00:23<10:03,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的分析结果，我需要查看这段对话文本。请您提供具体的对话内容，然后我可以帮助您判断是否存在诈骗风险。在您提供信息后，我将根据内容进行分析并以JSON格式输出判断结果。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:   8%|███████▎                                                                                 | 192/2348 [00:34<08:49,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的分析结果，我需要查看这段对话文本。请您提供具体的对话内容，然后我可以帮助您判断是否存在诈骗风险。在您提供信息后，我将根据内容进行分析并以JSON格式输出判断结果。例如：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": false\n",
      "}\n",
      "```\n",
      "\n",
      "如果对话中存在明显的诈骗迹象，例如要求汇款、提供个人信息、涉及不寻常交易等，结果可能会是 `true`。请提供详细信息以便进行分析。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:  59%|████████████████████████████████████████████████████▏                                   | 1392/2348 [03:08<03:52,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的判断，我需要完整的对话内容来进行分析。仅凭“发言人2: 就是”这一句话无法确定是否存在诈骗风险。通常在识别潜在诈骗时，会关注对话中的具体细节、请求或信息，例如涉及金钱交易、个人信息泄露、紧急情况等提示性内容。由于缺少完整上下文，我无法做出判断。因此，基于提供的信息：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": null\n",
      "}\n",
      "```\n",
      "\n",
      "请注意，如果后续有更多对话内容，请提供以便进行更详细的分析。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:  64%|████████████████████████████████████████████████████████▎                               | 1504/2348 [03:25<03:34,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的判断，我需要完整的对话上下文。然而，根据给出的片段 \"发言人2: 这是第一个\"，信息量非常有限，不足以确定是否存在诈骗风险。通常，判断对话中的诈骗风险需要考虑更多的上下文信息，例如发言人的后续言论、涉及的交易或请求的具体内容等。因此，基于这个片段，我无法做出准确判断。\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": null\n",
      "}\n",
      "```\n",
      "\n",
      "请注意，如果完整对话包含在后续提问中，我可以提供更精确的分析。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:  66%|█████████████████████████████████████████████████████████▊                              | 1544/2348 [03:35<04:05,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的判断，我需要完整的对话内容。然而，根据你提供的片段 \"发言人10: 那\"，信息量非常有限，不足以进行详细的分析。通常判断对话中的诈骗风险需要考虑整个对话的上下文、涉及的交易细节、请求的性质（如个人信息、财务信息等）以及任何紧迫性或压力性的语言使用。\n",
      "\n",
      "由于缺乏完整的信息，我无法准确判断这段对话是否包含诈骗风险。因此，基于提供的信息，我将答案设置为 `false`，表示在没有更多上下文的情况下，不能确定存在诈骗风险。\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": false\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:  80%|██████████████████████████████████████████████████████████████████████▍                 | 1880/2348 [04:17<01:41,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的分析结果，我需要查看这段对话文本。请您提供对话的内容，然后我可以帮助您判断是否存在诈骗风险。在您提供信息后，我将根据内容进行分析并以JSON格式返回结果。例如：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": false\n",
      "}\n",
      "```\n",
      "\n",
      "如果对话中存在明显的诈骗迹象，结果可能会是：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": true\n",
      "}\n",
      "```\n",
      "\n",
      "请提供具体的对话内容。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:  93%|█████████████████████████████████████████████████████████████████████████████████▊      | 2184/2348 [05:01<00:48,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的判断，我需要完整的对话内容。然而，根据您提供的片段 \"发言人4: 就是\"，信息量非常有限，不足以确定是否存在诈骗风险。通常分析对话中的诈骗风险需要考虑上下文、涉及的交易细节、请求的性质（如个人信息、财务信息等）以及任何紧迫性或压力的语言使用。\n",
      "\n",
      "由于缺乏足够的上下文信息，我无法准确判断这段对话是否包含诈骗风险。因此，基于提供的信息，我将输出的结果为：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": null\n",
      "}\n",
      "```\n",
      "\n",
      "这表示基于当前的信息，无法确定是否存在诈骗风险。建议在完整对话内容的情况下进行更详细的分析。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:  94%|██████████████████████████████████████████████████████████████████████████████████▍     | 2200/2348 [05:06<00:48,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的判断，我需要完整的对话上下文。然而，根据提供的片段 \"发言人10: 那\"，信息量非常有限，不足以确定是否存在诈骗风险。通常分析对话中的诈骗风险会考虑涉及的交易细节、紧急请求、个人信息索取、不寻常的优惠等内容。由于缺少这些关键信息，我无法做出判断。\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": null\n",
      "}\n",
      "```\n",
      "\n",
      "请注意，完整对话上下文对于此类分析至关重要。如果能提供更多对话内容，我可以给出更准确的判断。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress:  97%|█████████████████████████████████████████████████████████████████████████████████████▍  | 2280/2348 [05:19<00:17,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid json: 为了提供准确的判断，我需要完整的对话内容来进行分析。仅凭“发言人2: 其中。”这一句话无法确定是否存在诈骗风险。通常识别诈骗风险需要考虑对话的整体上下文、涉及的交易细节、紧急请求、个人信息泄露的风险、以及任何不寻常或可疑的行为模式等。\n",
      "\n",
      "因此，基于提供的信息片段，我无法做出判断。完整的对话内容是必要的。如果必须给出一个示例JSON输出，基于当前信息，结果可能是：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"is_fraud\": null\n",
      "}\n",
      "```\n",
      "\n",
      "这表示没有足够的信息来确定是否涉及诈骗。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2348/2348 [05:27<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1110, fp:55, fn:579, tp:604\n",
      "precision: 0.9165402124430956, recall: 0.5105663567202029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run evaluate.py\n",
    "model_path = '/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-7B-Instruct'\n",
    "evaluate(model_path, '', testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891d80b-5eff-4e74-b086-b9785b3027a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
